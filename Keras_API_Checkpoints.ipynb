{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Keras API's and Checkpoints implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# vi ~/.keras/keras.json - the config to point to TF or TH can be changed here.\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the various Keras API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The various packages for RNN, GRU, LSTM and Simple RNN\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The various Convolution and Pooling layers\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are various ways of regularization - includes the kernel_regularizer (on weights)\n",
    "# bias_regularizer (on the bias_weights), activity_regularizer (on the activation function)\n",
    "# apart from that there is Dropout used for regularization \n",
    "import  keras.regularizers.ActivityRegularizer\n",
    "import keras.regularizers.WeightRegularizer\n",
    "\n",
    "from keras.layers.core import Dropout # this has rate , noise_shape and seed (for random seed value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch normalization mostly used for GAN and Wavenet\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss functions and various categories of loss functions\n",
    "# 1. binary_accuracy, categorical_accuracy, sparse_categorical_accuracy and top_k_categorical_accuracy\n",
    "# 2. loss - mse, rmse , mae (mean absolute error), mape (mean percentage error), msle (mean squared logarithmic error)\n",
    "# 3. hinge loss - max(1- y_true * y_pred, 0) and squared hinge loss\n",
    "# 4. class log - binary cross entropy and categorical cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving and Loading the weights and the architecture of the model\n",
    "\n",
    "#save as json model or yaml model \n",
    "model.to_json() or model.to_yaml()\n",
    "#loading the model \n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "model_from_json(json_string)\n",
    "model_from_yaml(yaml_string)\n",
    "\n",
    "#only save the weights \n",
    "from keras.models import load_model \n",
    "del model # deletes the model.\n",
    "model.save('my_model.h5')\n",
    "load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#callback to stop early if a particular metric is matched \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Use of a callback method\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):     \n",
    "    def on_train_begin(self, logs={}):         \n",
    "        self.losses = []     \n",
    "    def on_batch_end(self, batch, logs={}):     \n",
    "        self.losses.append(logs.get('loss')) \n",
    "        model = Sequential() \n",
    "        model.add(Dense(10, input_dim=784, init='uniform')) \n",
    "        model.add(Activation('softmax')) \n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop') \n",
    "        history = LossHistory() \n",
    "        model.fit(X_train,Y_train, batch_size=128, nb_epoch=20,  verbose=0, callbacks=[history]) \n",
    "        print(history.losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Checkpoint to save the intermediate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All possible imports\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "np.random.seed(1671)\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 128 \n",
    "NUM_EPOCHS = 20 \n",
    "MODEL_DIR = \"/tmp\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 7s - loss: 0.2620 - acc: 0.9202 - val_loss: 0.1159 - val_acc: 0.9653\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 7s - loss: 0.1085 - acc: 0.9667 - val_loss: 0.0785 - val_acc: 0.9743\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 7s - loss: 0.0776 - acc: 0.9763 - val_loss: 0.0807 - val_acc: 0.9792\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s - loss: 0.0618 - acc: 0.9812 - val_loss: 0.0726 - val_acc: 0.9800\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0531 - acc: 0.9839 - val_loss: 0.0617 - val_acc: 0.9838\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0438 - acc: 0.9867 - val_loss: 0.0755 - val_acc: 0.9810\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0383 - acc: 0.9878 - val_loss: 0.0764 - val_acc: 0.9823\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0353 - acc: 0.9900 - val_loss: 0.0788 - val_acc: 0.9830\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0316 - acc: 0.9908 - val_loss: 0.0963 - val_acc: 0.9798\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0293 - acc: 0.9915 - val_loss: 0.0905 - val_acc: 0.9817\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0260 - acc: 0.9925 - val_loss: 0.0937 - val_acc: 0.9833\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0254 - acc: 0.9929 - val_loss: 0.0992 - val_acc: 0.9815\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0224 - acc: 0.9937 - val_loss: 0.0949 - val_acc: 0.9835\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 8s - loss: 0.0234 - acc: 0.9935 - val_loss: 0.0801 - val_acc: 0.9845\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0195 - acc: 0.9943 - val_loss: 0.0978 - val_acc: 0.9840\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0208 - acc: 0.9944 - val_loss: 0.1061 - val_acc: 0.9835\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0179 - acc: 0.9952 - val_loss: 0.1271 - val_acc: 0.9805\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0193 - acc: 0.9950 - val_loss: 0.1082 - val_acc: 0.9838\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0196 - acc: 0.9952 - val_loss: 0.0915 - val_acc: 0.9860\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0179 - acc: 0.9954 - val_loss: 0.0999 - val_acc: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12182a860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data() \n",
    "Xtrain = Xtrain.reshape(60000, 784).astype(\"float32\") / 255 \n",
    "Xtest = Xtest.reshape(10000, 784).astype(\"float32\") / 255 \n",
    "Ytrain = np_utils.to_categorical(ytrain, 10) \n",
    "Ytest = np_utils.to_categorical(ytest, 10) \n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape) \n",
    "\n",
    "model = Sequential() \n",
    "model.add(Dense(512, input_shape=(784,), activation=\"relu\")) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(512, activation=\"relu\")) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(10, activation=\"softmax\")) \n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# save best model \n",
    "checkpoint = ModelCheckpoint(filepath=os.path.join(MODEL_DIR, \"model-{epoch:02d}.h5\")) \n",
    "model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, nb_epoch=NUM_EPOCHS, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "TensorBoard callback only works with the TensorFlow backend.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-74f0af274427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Write data into tensorboard logs and then kick off tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/tmp/logs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# !tensorboard --logdir=/tmp/logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tkmacl9/anaconda/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, histogram_freq, write_graph, write_images)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BACKEND\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             raise Exception('TensorBoard callback only works '\n\u001b[0m\u001b[1;32m    460\u001b[0m                             'with the TensorFlow backend.')\n\u001b[1;32m    461\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: TensorBoard callback only works with the TensorFlow backend."
     ]
    }
   ],
   "source": [
    "#Write data into tensorboard logs and then kick off tensorboard\n",
    "keras.callbacks.TensorBoard(log_dir=\"/tmp/logs\", histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "!tensorboard --logdir=/tmp/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive visualizations on CNN layers - quiver\n",
    "https://github.com/jakebian/quiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install quiver_engine\n",
    "from quiver_engine import server\n",
    "server.launch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
